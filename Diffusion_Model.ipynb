{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNc1EshCMyPbPDEEqYw5Hi/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helya02/Diffusion-Model/blob/main/Diffusion_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoGy-cUQWehi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------\n",
        "# Diffusion hyperparameters\n",
        "# ---------------------------\n",
        "T = 200  # number of diffusion steps\n",
        "beta = torch.linspace(1e-4, 0.02, T)  # linear noise schedule\n",
        "alpha = 1. - beta\n",
        "alpha_bar = torch.cumprod(alpha, dim=0)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ---------------------------\n",
        "# Utility: Time Channel\n",
        "# ---------------------------\n",
        "def get_time_channel(t, shape):\n",
        "    # t is a tensor of shape (batch,)\n",
        "    # Normalize t to [0,1] and expand spatially.\n",
        "    t_norm = (t.float() / T).view(-1, 1, 1, 1)\n",
        "    return t_norm.expand(-1, shape[1], shape[2], shape[3])\n",
        "\n",
        "# ---------------------------\n",
        "# q_sample: forward diffusion process\n",
        "# ---------------------------\n",
        "def q_sample(x0, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x0)\n",
        "    # Index alpha_bar at time t for each sample and reshape for broadcasting.\n",
        "    sqrt_alpha_bar = torch.sqrt(alpha_bar[t]).view(-1, 1, 1, 1).to(x0.device)\n",
        "    sqrt_one_minus_alpha_bar = torch.sqrt(1 - alpha_bar[t]).view(-1, 1, 1, 1).to(x0.device)\n",
        "    return sqrt_alpha_bar * x0 + sqrt_one_minus_alpha_bar * noise\n",
        "\n",
        "# ---------------------------\n",
        "# Dataset for Super-Resolution\n",
        "# ---------------------------\n",
        "# We define a custom dataset that returns:\n",
        "#   - a high-res image (32×32, normalized to [-1,1])\n",
        "#   - a “low-res” image: downsampled to 16×16 then upsampled back to 32×32.\n",
        "class CIFAR10_SR(CIFAR10):\n",
        "    def __init__(self, root, train=True, transform=None, download=False, low_res_size=16):\n",
        "        super().__init__(root=root, train=train, transform=transform, download=download)\n",
        "        self.low_res_size = low_res_size\n",
        "        self.low_res_transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((low_res_size, low_res_size), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.Resize((32, 32), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda x: x * 2 - 1)  # scale [0,1] -> [-1,1]\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # High-res image using the given transform\n",
        "        img, label = super().__getitem__(index)\n",
        "        # Create low-res version\n",
        "        low_res_img = self.low_res_transform(img)\n",
        "        return img, low_res_img\n",
        "\n",
        "# Transform: convert image to tensor and scale to [-1,1]\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x * 2 - 1)\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 training dataset\n",
        "train_dataset = CIFAR10_SR(root='./data', train=True, transform=transform, download=True, low_res_size=16)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "# ---------------------------\n",
        "# Conditional Diffusion Model\n",
        "# ---------------------------\n",
        "# Our model takes three inputs:\n",
        "#   - x: the noisy high-res image (3 channels)\n",
        "#   - low_res: the low-res image (3 channels)\n",
        "#   - t: the time step (added as an extra channel)\n",
        "# We concatenate these along the channel dimension (3+3+1=7 channels total).\n",
        "class ConditionalDiffusionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(7, 64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(64, 3, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x, low_res, t):\n",
        "        # Create a time channel from t\n",
        "        t_channel = get_time_channel(t, x.shape)\n",
        "        # Concatenate along channels: [x (3), low_res (3), t_channel (1)] → (7 channels)\n",
        "        x_in = torch.cat([x, low_res, t_channel], dim=1)\n",
        "        h = self.relu(self.conv1(x_in))\n",
        "        h = self.relu(self.conv2(h))\n",
        "        h = self.relu(self.conv3(h))\n",
        "        out = self.conv4(h)\n",
        "        return out\n",
        "\n",
        "model = ConditionalDiffusionModel().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ---------------------------\n",
        "# Training Loop\n",
        "# ---------------------------\n",
        "epochs = 5  # For demonstration; increase epochs for better results.\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (high_res, low_res) in enumerate(train_loader):\n",
        "        high_res = high_res.to(device)  # Ground truth image\n",
        "        low_res = low_res.to(device)    # Condition: blurry low-res image\n",
        "        batch_size = high_res.size(0)\n",
        "        # Sample random timesteps for each image\n",
        "        t = torch.randint(0, T, (batch_size,), device=device)\n",
        "        noise = torch.randn_like(high_res)\n",
        "        x_noisy = q_sample(high_res, t, noise)\n",
        "        # Model predicts the noise added\n",
        "        noise_pred = model(x_noisy, low_res, t)\n",
        "        loss = F.mse_loss(noise_pred, noise)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Sampling: Super-Resolution Generation\n",
        "# ---------------------------\n",
        "@torch.no_grad()\n",
        "def sample_super_resolution(model, low_res, steps=T):\n",
        "    # low_res: conditioned low-res image [B, 3, 32, 32]\n",
        "    model.eval()\n",
        "    batch_size = low_res.size(0)\n",
        "    # Start from pure Gaussian noise\n",
        "    x = torch.randn(batch_size, 3, 32, 32).to(device)\n",
        "    for t in reversed(range(steps)):\n",
        "        t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
        "        pred_noise = model(x, low_res, t_tensor)\n",
        "        alpha_t = alpha[t]\n",
        "        alpha_bar_t = alpha_bar[t]\n",
        "        beta_t = beta[t]\n",
        "        # Reverse diffusion update\n",
        "        x = (1 / torch.sqrt(alpha_t)) * (x - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * pred_noise)\n",
        "        if t > 0:\n",
        "            noise = torch.randn_like(x)\n",
        "            x = x + torch.sqrt(beta_t) * noise\n",
        "    return x\n",
        "\n",
        "# ---------------------------\n",
        "# Visualize Results\n",
        "# ---------------------------\n",
        "# Load test dataset\n",
        "test_dataset = CIFAR10_SR(root='./data', train=False, transform=transform, download=True, low_res_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
        "high_res_test, low_res_test = next(iter(test_loader))\n",
        "high_res_test = high_res_test.to(device)\n",
        "low_res_test = low_res_test.to(device)\n",
        "\n",
        "# Generate super-resolved samples\n",
        "samples = sample_super_resolution(model, low_res_test)\n",
        "\n",
        "# Create a grid to display:\n",
        "# - Top row: low-res (condition)\n",
        "# - Middle row: model output (super-resolved)\n",
        "# - Bottom row: ground truth high-res\n",
        "grid = torchvision.utils.make_grid(torch.cat([low_res_test, samples, high_res_test], dim=0), nrow=16, normalize=True)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.imshow(np.transpose(grid.cpu().numpy(), (1, 2, 0)))\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ]
}